{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import math\r\n",
    "import csv\r\n",
    "import random\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\r\n",
    "# failai kuriuos norime transformuoti\r\n",
    "names = [r'Raw_Data\\02-14-2018.csv']\r\n",
    "\r\n",
    "# Po kiek eluciu isimti is failo\r\n",
    "Ch_size = 500000\r\n",
    "\r\n",
    "# ar pirmas nuskaitymas\r\n",
    "head = True\r\n",
    "\r\n",
    "# for ciklo pradzia\r\n",
    "for n in names:\r\n",
    "    # nuskaitome po chunka\r\n",
    "    for chunk in pd.read_csv(n, chunksize=Ch_size, low_memory = False):\r\n",
    "        # isiemame visus NAN ir INF\r\n",
    "        chunk = chunk[~chunk.isin([np.nan, np.inf, -np.inf]).any(1)]\r\n",
    "        # isiemame laiko stulpeli\r\n",
    "        chunk = chunk.drop(['Timestamp'], axis=1)\r\n",
    "\r\n",
    "\r\n",
    "        # isrenkame stulpeliu pavadinimus\r\n",
    "        if head == True:\r\n",
    "            columns = chunk.columns.values\r\n",
    "\r\n",
    "        # atskiriam kur yra reiksmes kur yra tipas\r\n",
    "        X = chunk.iloc[:, 0:-1].values\r\n",
    "        y = chunk.iloc[:, -1].values\r\n",
    "\r\n",
    "        # suzimime kur yra normalus ivykis (0) kur ataka (1)\r\n",
    "        suby = []\r\n",
    "        for i in range(len(y)):\r\n",
    "            if y[i] == 'Benign' or y[i] == 'Normal':\r\n",
    "                suby.append(0)\r\n",
    "            else:\r\n",
    "                suby.append(1)\r\n",
    "        y = suby.copy()\r\n",
    "        del suby\r\n",
    "    \r\n",
    "        # suskirstomai train ir test datasetus su kuriais bus mokinamas ir testuojamas ANN\r\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)\r\n",
    "\r\n",
    "        # datasetai yra tranformuojami. Nezinau ar cia as gerai darau, bet kolkas geresnio budo nezinau\r\n",
    "        sc = StandardScaler()\r\n",
    "        X_train = sc.fit_transform(X_train)\r\n",
    "        X_test = sc.transform(X_test)\r\n",
    "\r\n",
    "        # sudedami atgal i dataframus\r\n",
    "        training_dataset = np.column_stack((X_train, y_train))\r\n",
    "        test_dataset = np.column_stack((X_test, y_test))\r\n",
    "\r\n",
    "        training_dataset = pd.DataFrame(data=training_dataset)\r\n",
    "        test_dataset = pd.DataFrame(data=test_dataset)\r\n",
    "\r\n",
    "        # sudedami stulpeliu pavadinimai\r\n",
    "        training_dataset.columns = columns\r\n",
    "        test_dataset.columns = columns\r\n",
    "\r\n",
    "\r\n",
    "        # training_dataset, test_dataset = train_test_split(chunk, test_size = 0.2, random_state = 10)\r\n",
    "\r\n",
    "        # idedti i .csv failus\r\n",
    "        if head:\r\n",
    "            test_dataset.to_csv(r'Temp_Data\\test_data.csv')\r\n",
    "            training_dataset.to_csv(r'Temp_Data\\train_data.csv')\r\n",
    "            head = False\r\n",
    "        else:\r\n",
    "            test_dataset.to_csv(r'Temp_Data\\test_data.csv', mode='a', header=False)\r\n",
    "            training_dataset.to_csv(r'Temp_Data\\train_data.csv', mode='a', header=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "988ccdee98c6f280c02691a59536500eb11bb1fd9b0fe1ccc3ec258f0162fdd8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}