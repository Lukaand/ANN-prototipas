{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "988ccdee98c6f280c02691a59536500eb11bb1fd9b0fe1ccc3ec258f0162fdd8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import math\r\n",
    "import csv\r\n",
    "import random\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "import sys"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\r\n",
    "# names = [r'CSV\\02-14-2018.csv',\r\n",
    "#          r'CSV\\02-15-2018.csv', \r\n",
    "#          r'CSV\\02-16-2018.csv', \r\n",
    "#          r'CSV\\02-20-2018.csv', \r\n",
    "#          r'CSV\\02-21-2018.csv', \r\n",
    "#          r'CSV\\02-21-2018.csv', \r\n",
    "#          r'CSV\\02-22-2018.csv', \r\n",
    "#          r'CSV\\02-23-2018.csv', \r\n",
    "#          r'CSV\\02-28-2018.csv', \r\n",
    "#          r'CSV\\03-01-2018.csv',\r\n",
    "#          r'CSV\\03-02-2018.csv',\r\n",
    "#          r'C:\\Users\\lukut\\Desktop\\Darbas\\data\\testbed-12jun.pcap_Flow.csv',\r\n",
    "#          r'C:\\Users\\lukut\\Desktop\\Darbas\\data\\testbed-13jun.pcap_Flow.csv',\r\n",
    "#          r'C:\\Users\\lukut\\Desktop\\Darbas\\data\\testbed-14jun.pcap_Flow.csv',\r\n",
    "#          r'C:\\Users\\lukut\\Desktop\\Darbas\\data\\testbed-15jun.pcap_Flow.csv',\r\n",
    "#          r'C:\\Users\\lukut\\Desktop\\Darbas\\data\\testbed-16jun.pcap_Flow.csv',\r\n",
    "#          r'C:\\Users\\lukut\\Desktop\\Darbas\\data\\testbed-17jun.pcap_Flow.csv']\r\n",
    "\r\n",
    "\r\n",
    "names = [r'CSV\\02-14-2018.csv',\r\n",
    "         r'CSV\\02-15-2018.csv', \r\n",
    "         r'CSV\\02-16-2018.csv', \r\n",
    "         r'CSV\\02-20-2018.csv', \r\n",
    "         r'CSV\\02-21-2018.csv',  \r\n",
    "         r'CSV\\02-22-2018.csv', \r\n",
    "         r'CSV\\02-23-2018.csv', \r\n",
    "         r'CSV\\02-28-2018.csv', \r\n",
    "         r'CSV\\03-01-2018.csv',\r\n",
    "         r'CSV\\03-02-2018.csv']\r\n",
    "\r\n",
    "\r\n",
    "# names = [r'CSV\\02-20-2018.csv']\r\n",
    "\r\n",
    "Ch_size = 500000\r\n",
    "head = True\r\n",
    "for n in names:\r\n",
    "    print(n)\r\n",
    "    for chunk in pd.read_csv(n, chunksize=Ch_size, low_memory = False):\r\n",
    "        print(\"here\")\r\n",
    "\r\n",
    "        chunk = chunk[~chunk.isin([np.nan, np.inf, -np.inf]).any(1)]\r\n",
    "        chunk = chunk.drop(['Timestamp'], axis=1)\r\n",
    "\r\n",
    "        chunk = chunk[pd.to_numeric(chunk['Dst Port'], errors='coerce').notnull()]\r\n",
    "        chunk['Dst Port'] = chunk['Dst Port'].astype(float)\r\n",
    "        # print(chunk)\r\n",
    "\r\n",
    "        print(len(chunk))\r\n",
    "\r\n",
    "        if head == True:\r\n",
    "            columns = chunk.columns.values\r\n",
    "\r\n",
    "        if len(chunk.columns.values) == 83:\r\n",
    "            X = chunk.iloc[:, 4:-1].values\r\n",
    "            y = chunk.iloc[:, -1].values\r\n",
    "            print(len(chunk.columns.values))\r\n",
    "        else:\r\n",
    "            X = chunk.iloc[:, 0:-1].values\r\n",
    "            y = chunk.iloc[:, -1].values\r\n",
    "            print(len(chunk.columns.values))\r\n",
    "\r\n",
    "        suby = []\r\n",
    "        for i in range(len(y)):\r\n",
    "            if y[i] == 'Benign' or y[i] == 'Normal':\r\n",
    "                suby.append(0)\r\n",
    "            else:\r\n",
    "                suby.append(1)\r\n",
    "        y = suby.copy()\r\n",
    "        del suby\r\n",
    "    \r\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\r\n",
    "        # print(\"before transform\")\r\n",
    "        # print(len(X_train))\r\n",
    "        # print(len(y_test))\r\n",
    "        # print(len(X_train[0]))\r\n",
    "\r\n",
    "        sc = StandardScaler()\r\n",
    "        X_train = sc.fit_transform(X_train)\r\n",
    "        X_test = sc.transform(X_test)\r\n",
    "\r\n",
    "        # print(\"after transform\")\r\n",
    "        # print(len(X_train))\r\n",
    "        # print(len(X_train[0]))\r\n",
    "\r\n",
    "        training_dataset = np.column_stack((X_train, y_train))\r\n",
    "        test_dataset = np.column_stack((X_test, y_test))\r\n",
    "\r\n",
    "        # print(\"after condensation\")\r\n",
    "        # print(len(training_dataset))\r\n",
    "        # print(len(test_dataset))\r\n",
    "        # print(len(training_dataset[0]))\r\n",
    "        # print(len(test_dataset[0]))\r\n",
    "\r\n",
    "        training_dataset = pd.DataFrame(data=training_dataset)\r\n",
    "        test_dataset = pd.DataFrame(data=test_dataset)\r\n",
    "\r\n",
    "\r\n",
    "        training_dataset.columns = columns\r\n",
    "        test_dataset.columns = columns\r\n",
    "\r\n",
    "\r\n",
    "        # training_dataset, test_dataset = train_test_split(chunk, test_size = 0.2, random_state = 10)\r\n",
    "\r\n",
    "        # idedti i .csv failus\r\n",
    "        if head:\r\n",
    "            test_dataset.to_csv(r'C:\\Users\\lukut\\Desktop\\Darbas\\2018\\Split_data\\test_data.csv')\r\n",
    "            training_dataset.to_csv(r'C:\\Users\\lukut\\Desktop\\Darbas\\2018\\Split_data\\train_data.csv')\r\n",
    "            head = False\r\n",
    "        else:\r\n",
    "            test_dataset.to_csv(r'C:\\Users\\lukut\\Desktop\\Darbas\\2018\\Split_data\\test_data.csv', mode='a', header=False)\r\n",
    "            training_dataset.to_csv(r'C:\\Users\\lukut\\Desktop\\Darbas\\2018\\Split_data\\train_data.csv', mode='a', header=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CSV\\02-14-2018.csv\n",
      "here\n",
      "499313\n",
      "79\n",
      "here\n",
      "497104\n",
      "79\n",
      "here\n",
      "48334\n",
      "79\n",
      "CSV\\02-15-2018.csv\n",
      "here\n",
      "496301\n",
      "79\n",
      "here\n",
      "495980\n",
      "79\n",
      "here\n",
      "48267\n",
      "79\n",
      "CSV\\02-16-2018.csv\n",
      "here\n",
      "500000\n",
      "79\n",
      "here\n",
      "499999\n",
      "79\n",
      "here\n",
      "48575\n",
      "79\n",
      "CSV\\02-20-2018.csv\n",
      "here\n",
      "500000\n",
      "83\n",
      "here\n",
      "497378\n",
      "83\n",
      "here\n",
      "497090\n",
      "83\n",
      "here\n",
      "496831\n",
      "83\n",
      "here\n",
      "495244\n",
      "83\n",
      "here\n",
      "495052\n",
      "83\n",
      "here\n",
      "494978\n",
      "83\n",
      "here\n",
      "494861\n",
      "83\n",
      "here\n",
      "494849\n",
      "83\n",
      "here\n",
      "494382\n",
      "83\n",
      "here\n",
      "494756\n",
      "83\n",
      "here\n",
      "494603\n",
      "83\n",
      "here\n",
      "496811\n",
      "83\n",
      "here\n",
      "496793\n",
      "83\n",
      "here\n",
      "497706\n",
      "83\n",
      "here\n",
      "447961\n",
      "83\n",
      "CSV\\02-21-2018.csv\n",
      "here\n",
      "500000\n",
      "79\n",
      "here\n",
      "500000\n",
      "79\n",
      "here\n",
      "48575\n",
      "79\n",
      "CSV\\02-22-2018.csv\n",
      "here\n",
      "497361\n",
      "79\n",
      "here\n",
      "497230\n",
      "79\n",
      "here\n",
      "48374\n",
      "79\n",
      "CSV\\02-23-2018.csv\n",
      "here\n",
      "497156\n",
      "79\n",
      "here\n",
      "497284\n",
      "79\n",
      "here\n",
      "48427\n",
      "79\n",
      "CSV\\02-28-2018.csv\n",
      "here\n",
      "496714\n",
      "79\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f584204be49f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \"\"\"\n\u001b[0;32m    765\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[0;32m    767\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m                                 force_all_finite='allow-nan', reset=first_call)\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "for chunk in pd.read_csv(r'C:\\Users\\lukut\\Desktop\\Darbas\\data\\testbed-12jun.pcap_Flow.csv', chunksize=500000, low_memory = False):\r\n",
    "    columns = chunk.columns.values\r\n",
    "    print(columns)\r\n",
    "    print(len(columns))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Flow ID' 'Src IP' 'Src Port' 'Dst IP' 'Dst Port' 'Protocol' 'Timestamp'\n",
      " 'Flow Duration' 'Total Fwd Packet' 'Total Bwd packets'\n",
      " 'Total Length of Fwd Packet' 'Total Length of Bwd Packet'\n",
      " 'Fwd Packet Length Max' 'Fwd Packet Length Min' 'Fwd Packet Length Mean'\n",
      " 'Fwd Packet Length Std' 'Bwd Packet Length Max' 'Bwd Packet Length Min'\n",
      " 'Bwd Packet Length Mean' 'Bwd Packet Length Std' 'Flow Bytes/s'\n",
      " 'Flow Packets/s' 'Flow IAT Mean' 'Flow IAT Std' 'Flow IAT Max'\n",
      " 'Flow IAT Min' 'Fwd IAT Total' 'Fwd IAT Mean' 'Fwd IAT Std' 'Fwd IAT Max'\n",
      " 'Fwd IAT Min' 'Bwd IAT Total' 'Bwd IAT Mean' 'Bwd IAT Std' 'Bwd IAT Max'\n",
      " 'Bwd IAT Min' 'Fwd PSH Flags' 'Bwd PSH Flags' 'Fwd URG Flags'\n",
      " 'Bwd URG Flags' 'Fwd Header Length' 'Bwd Header Length' 'Fwd Packets/s'\n",
      " 'Bwd Packets/s' 'Packet Length Min' 'Packet Length Max'\n",
      " 'Packet Length Mean' 'Packet Length Std' 'Packet Length Variance'\n",
      " 'FIN Flag Count' 'SYN Flag Count' 'RST Flag Count' 'PSH Flag Count'\n",
      " 'ACK Flag Count' 'URG Flag Count' 'CWR Flag Count' 'ECE Flag Count'\n",
      " 'Down/Up Ratio' 'Average Packet Size' 'Fwd Segment Size Avg'\n",
      " 'Bwd Segment Size Avg' 'Fwd Bytes/Bulk Avg' 'Fwd Packet/Bulk Avg'\n",
      " 'Fwd Bulk Rate Avg' 'Bwd Bytes/Bulk Avg' 'Bwd Packet/Bulk Avg'\n",
      " 'Bwd Bulk Rate Avg' 'Subflow Fwd Packets' 'Subflow Fwd Bytes'\n",
      " 'Subflow Bwd Packets' 'Subflow Bwd Bytes' 'FWD Init Win Bytes'\n",
      " 'Bwd Init Win Bytes' 'Fwd Act Data Pkts' 'Fwd Seg Size Min' 'Active Mean'\n",
      " 'Active Std' 'Active Max' 'Active Min' 'Idle Mean' 'Idle Std' 'Idle Max'\n",
      " 'Idle Min' 'Label']\n",
      "84\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}